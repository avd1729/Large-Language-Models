{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a93ce20a",
   "metadata": {
    "papermill": {
     "duration": 0.006339,
     "end_time": "2025-06-19T07:01:10.014592",
     "exception": false,
     "start_time": "2025-06-19T07:01:10.008253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Setting up the environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cdd47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:10.025985Z",
     "iopub.status.busy": "2025-06-19T07:01:10.025141Z",
     "iopub.status.idle": "2025-06-19T07:01:10.033280Z",
     "shell.execute_reply": "2025-06-19T07:01:10.032450Z"
    },
    "papermill": {
     "duration": 0.01559,
     "end_time": "2025-06-19T07:01:10.035011",
     "exception": false,
     "start_time": "2025-06-19T07:01:10.019421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3610df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:10.046298Z",
     "iopub.status.busy": "2025-06-19T07:01:10.046038Z",
     "iopub.status.idle": "2025-06-19T07:01:20.619321Z",
     "shell.execute_reply": "2025-06-19T07:01:20.618545Z"
    },
    "papermill": {
     "duration": 10.581516,
     "end_time": "2025-06-19T07:01:20.621566",
     "exception": false,
     "start_time": "2025-06-19T07:01:10.040050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7770e896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:20.633218Z",
     "iopub.status.busy": "2025-06-19T07:01:20.632674Z",
     "iopub.status.idle": "2025-06-19T07:01:20.929844Z",
     "shell.execute_reply": "2025-06-19T07:01:20.929036Z"
    },
    "papermill": {
     "duration": 0.305189,
     "end_time": "2025-06-19T07:01:20.931932",
     "exception": false,
     "start_time": "2025-06-19T07:01:20.626743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "2638744/2638744 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
    "path = tf.keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
    "                               extract=True)\n",
    "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc88029d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:20.944309Z",
     "iopub.status.busy": "2025-06-19T07:01:20.943551Z",
     "iopub.status.idle": "2025-06-19T07:01:21.517404Z",
     "shell.execute_reply": "2025-06-19T07:01:21.516672Z"
    },
    "papermill": {
     "duration": 0.582205,
     "end_time": "2025-06-19T07:01:21.519498",
     "exception": false,
     "start_time": "2025-06-19T07:01:20.937293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
    "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
    "np.random.shuffle(pairs)\n",
    "sentences_en, sentences_es = zip(*pairs)  # separates the pairs into 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "262b2d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:21.531427Z",
     "iopub.status.busy": "2025-06-19T07:01:21.530656Z",
     "iopub.status.idle": "2025-06-19T07:01:21.535829Z",
     "shell.execute_reply": "2025-06-19T07:01:21.534826Z"
    },
    "papermill": {
     "duration": 0.012729,
     "end_time": "2025-06-19T07:01:21.537511",
     "exception": false,
     "start_time": "2025-06-19T07:01:21.524782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How boring! => Qué aburrimiento!\n",
      "I love sports. => Adoro el deporte.\n",
      "Would you like to swap jobs? => Te gustaría que intercambiemos los trabajos?\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(sentences_en[i], \"=>\", sentences_es[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0611f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:21.548791Z",
     "iopub.status.busy": "2025-06-19T07:01:21.548127Z",
     "iopub.status.idle": "2025-06-19T07:01:36.327105Z",
     "shell.execute_reply": "2025-06-19T07:01:36.326237Z"
    },
    "papermill": {
     "duration": 14.787022,
     "end_time": "2025-06-19T07:01:36.329467",
     "exception": false,
     "start_time": "2025-06-19T07:01:21.542445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "max_length = 50\n",
    "text_vec_layer_en = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_es = tf.keras.layers.TextVectorization(\n",
    "    vocab_size, output_sequence_length=max_length)\n",
    "text_vec_layer_en.adapt(sentences_en)\n",
    "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ebaa6e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:36.341838Z",
     "iopub.status.busy": "2025-06-19T07:01:36.341516Z",
     "iopub.status.idle": "2025-06-19T07:01:36.351150Z",
     "shell.execute_reply": "2025-06-19T07:01:36.350444Z"
    },
    "papermill": {
     "duration": 0.017835,
     "end_time": "2025-06-19T07:01:36.353079",
     "exception": false,
     "start_time": "2025-06-19T07:01:36.335244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'the', 'i', 'to', 'you', 'tom', 'a', 'is', 'he']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_en.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54081393",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:36.365105Z",
     "iopub.status.busy": "2025-06-19T07:01:36.364278Z",
     "iopub.status.idle": "2025-06-19T07:01:36.372059Z",
     "shell.execute_reply": "2025-06-19T07:01:36.371247Z"
    },
    "papermill": {
     "duration": 0.015566,
     "end_time": "2025-06-19T07:01:36.373766",
     "exception": false,
     "start_time": "2025-06-19T07:01:36.358200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'startofseq', 'endofseq', 'de', 'que', 'a', 'no', 'tom', 'la']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vec_layer_es.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41dea184",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:36.385907Z",
     "iopub.status.busy": "2025-06-19T07:01:36.385610Z",
     "iopub.status.idle": "2025-06-19T07:01:37.210982Z",
     "shell.execute_reply": "2025-06-19T07:01:37.210022Z"
    },
    "papermill": {
     "duration": 0.834273,
     "end_time": "2025-06-19T07:01:37.213300",
     "exception": false,
     "start_time": "2025-06-19T07:01:36.379027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = tf.constant(sentences_en[:100_000])\n",
    "X_valid = tf.constant(sentences_en[100_000:])\n",
    "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
    "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])\n",
    "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
    "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b41f0fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:37.226079Z",
     "iopub.status.busy": "2025-06-19T07:01:37.225461Z",
     "iopub.status.idle": "2025-06-19T07:01:37.242012Z",
     "shell.execute_reply": "2025-06-19T07:01:37.241052Z"
    },
    "papermill": {
     "duration": 0.024599,
     "end_time": "2025-06-19T07:01:37.243630",
     "exception": false,
     "start_time": "2025-06-19T07:01:37.219031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42) \n",
    "encoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)\n",
    "decoder_inputs = tf.keras.layers.Input(shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77749dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:37.255657Z",
     "iopub.status.busy": "2025-06-19T07:01:37.255386Z",
     "iopub.status.idle": "2025-06-19T07:01:37.355673Z",
     "shell.execute_reply": "2025-06-19T07:01:37.354708Z"
    },
    "papermill": {
     "duration": 0.108599,
     "end_time": "2025-06-19T07:01:37.357709",
     "exception": false,
     "start_time": "2025-06-19T07:01:37.249110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
    "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
    "encoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "decoder_embedding_layer = tf.keras.layers.Embedding(vocab_size, embed_size,\n",
    "                                                    mask_zero=True)\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750e3a95",
   "metadata": {
    "papermill": {
     "duration": 0.005255,
     "end_time": "2025-06-19T07:01:37.368434",
     "exception": false,
     "start_time": "2025-06-19T07:01:37.363179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Bidirectional RNNs - Sequence to Sequence Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e141501b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:37.380041Z",
     "iopub.status.busy": "2025-06-19T07:01:37.379767Z",
     "iopub.status.idle": "2025-06-19T07:01:37.409546Z",
     "shell.execute_reply": "2025-06-19T07:01:37.408587Z"
    },
    "papermill": {
     "duration": 0.038013,
     "end_time": "2025-06-19T07:01:37.411620",
     "exception": false,
     "start_time": "2025-06-19T07:01:37.373607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code – ensures reproducibility on CPU\n",
    "encoder = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(256, return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c893763a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:37.423581Z",
     "iopub.status.busy": "2025-06-19T07:01:37.423303Z",
     "iopub.status.idle": "2025-06-19T07:01:39.100670Z",
     "shell.execute_reply": "2025-06-19T07:01:39.099872Z"
    },
    "papermill": {
     "duration": 1.68591,
     "end_time": "2025-06-19T07:01:39.102942",
     "exception": false,
     "start_time": "2025-06-19T07:01:37.417032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
    "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
    "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8698d995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:01:39.116597Z",
     "iopub.status.busy": "2025-06-19T07:01:39.115852Z",
     "iopub.status.idle": "2025-06-19T07:12:45.172718Z",
     "shell.execute_reply": "2025-06-19T07:12:45.171864Z"
    },
    "papermill": {
     "duration": 666.065464,
     "end_time": "2025-06-19T07:12:45.174461",
     "exception": false,
     "start_time": "2025-06-19T07:01:39.108997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3125/3125 [==============================] - 108s 30ms/step - loss: 2.7433 - accuracy: 0.4549 - val_loss: 1.9523 - val_accuracy: 0.5593\n",
      "Epoch 2/10\n",
      "3125/3125 [==============================] - 63s 20ms/step - loss: 1.6614 - accuracy: 0.6094 - val_loss: 1.5182 - val_accuracy: 0.6365\n",
      "Epoch 3/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 1.3186 - accuracy: 0.6732 - val_loss: 1.3524 - val_accuracy: 0.6698\n",
      "Epoch 4/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 1.1262 - accuracy: 0.7115 - val_loss: 1.2858 - val_accuracy: 0.6841\n",
      "Epoch 5/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 0.9852 - accuracy: 0.7398 - val_loss: 1.2544 - val_accuracy: 0.6890\n",
      "Epoch 6/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 0.8702 - accuracy: 0.7648 - val_loss: 1.2526 - val_accuracy: 0.6918\n",
      "Epoch 7/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 0.7729 - accuracy: 0.7858 - val_loss: 1.2701 - val_accuracy: 0.6920\n",
      "Epoch 8/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 0.6858 - accuracy: 0.8065 - val_loss: 1.2930 - val_accuracy: 0.6913\n",
      "Epoch 9/10\n",
      "3125/3125 [==============================] - 62s 20ms/step - loss: 0.6109 - accuracy: 0.8243 - val_loss: 1.3331 - val_accuracy: 0.6886\n",
      "Epoch 10/10\n",
      "3125/3125 [==============================] - 61s 19ms/step - loss: 0.5465 - accuracy: 0.8406 - val_loss: 1.3707 - val_accuracy: 0.6860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7c579dd45930>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = tf.keras.layers.LSTM(512, return_sequences=True)\n",
    "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)\n",
    "output_layer = tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
    "Y_proba = output_layer(decoder_outputs)\n",
    "model = tf.keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
    "                       outputs=[Y_proba])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
    "          validation_data=((X_valid, X_valid_dec), Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb0075",
   "metadata": {
    "papermill": {
     "duration": 0.481887,
     "end_time": "2025-06-19T07:12:46.138711",
     "exception": false,
     "start_time": "2025-06-19T07:12:45.656824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Greedy Decoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a47c0e9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:12:47.151173Z",
     "iopub.status.busy": "2025-06-19T07:12:47.150829Z",
     "iopub.status.idle": "2025-06-19T07:12:47.156550Z",
     "shell.execute_reply": "2025-06-19T07:12:47.155659Z"
    },
    "papermill": {
     "duration": 0.492543,
     "end_time": "2025-06-19T07:12:47.158207",
     "exception": false,
     "start_time": "2025-06-19T07:12:46.665664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence_en):\n",
    "    translation = \"\"\n",
    "    for word_idx in range(max_length):\n",
    "        X = np.array([sentence_en])  # encoder input \n",
    "        X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
    "        y_proba = model.predict((X, X_dec))[0, word_idx]  # last token's probas\n",
    "        predicted_word_id = np.argmax(y_proba)\n",
    "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
    "        if predicted_word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + predicted_word\n",
    "    return translation.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e56ed0a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:12:48.231641Z",
     "iopub.status.busy": "2025-06-19T07:12:48.231229Z",
     "iopub.status.idle": "2025-06-19T07:12:52.110344Z",
     "shell.execute_reply": "2025-06-19T07:12:52.109485Z"
    },
    "papermill": {
     "duration": 4.366097,
     "end_time": "2025-06-19T07:12:52.112153",
     "exception": false,
     "start_time": "2025-06-19T07:12:47.746056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta el fútbol'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3112f8bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:12:53.149962Z",
     "iopub.status.busy": "2025-06-19T07:12:53.149415Z",
     "iopub.status.idle": "2025-06-19T07:12:53.843882Z",
     "shell.execute_reply": "2025-06-19T07:12:53.843059Z"
    },
    "papermill": {
     "duration": 1.175223,
     "end_time": "2025-06-19T07:12:53.845487",
     "exception": false,
     "start_time": "2025-06-19T07:12:52.670264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta [UNK] ella antes de ir a la playa'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"I like soccer and also going to the beach\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e1990",
   "metadata": {
    "papermill": {
     "duration": 0.479271,
     "end_time": "2025-06-19T07:12:54.881322",
     "exception": false,
     "start_time": "2025-06-19T07:12:54.402051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Beam Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efd735a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:12:55.903030Z",
     "iopub.status.busy": "2025-06-19T07:12:55.902353Z",
     "iopub.status.idle": "2025-06-19T07:12:55.910580Z",
     "shell.execute_reply": "2025-06-19T07:12:55.909756Z"
    },
    "papermill": {
     "duration": 0.545171,
     "end_time": "2025-06-19T07:12:55.912400",
     "exception": false,
     "start_time": "2025-06-19T07:12:55.367229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beam_search(sentence_en, beam_width, verbose=False):\n",
    "    X = np.array([sentence_en])  # encoder input\n",
    "    X_dec = np.array([\"startofseq\"])  # decoder input\n",
    "    y_proba = model.predict((X, X_dec))[0, 0]  # first token's probas\n",
    "    top_k = tf.math.top_k(y_proba, k=beam_width)\n",
    "    top_translations = [  # list of best (log_proba, translation)\n",
    "        (np.log(word_proba), text_vec_layer_es.get_vocabulary()[word_id])\n",
    "        for word_proba, word_id in zip(top_k.values, top_k.indices)\n",
    "    ]\n",
    "    \n",
    "    # extra code – displays the top first words in verbose mode\n",
    "    if verbose:\n",
    "        print(\"Top first words:\", top_translations)\n",
    "\n",
    "    for idx in range(1, max_length):\n",
    "        candidates = []\n",
    "        for log_proba, translation in top_translations:\n",
    "            if translation.endswith(\"endofseq\"):\n",
    "                candidates.append((log_proba, translation))\n",
    "                continue  # translation is finished, so don't try to extend it\n",
    "            X = np.array([sentence_en])  # encoder input\n",
    "            X_dec = np.array([\"startofseq \" + translation])  # decoder input\n",
    "            y_proba = model.predict((X, X_dec))[0, idx]  # last token's proba\n",
    "            for word_id, word_proba in enumerate(y_proba):\n",
    "                word = text_vec_layer_es.get_vocabulary()[word_id]\n",
    "                candidates.append((log_proba + np.log(word_proba),\n",
    "                                   f\"{translation} {word}\"))\n",
    "        top_translations = sorted(candidates, reverse=True)[:beam_width]\n",
    "\n",
    "        # extra code – displays the top translation so far in verbose mode\n",
    "        if verbose:\n",
    "            print(\"Top translations so far:\", top_translations)\n",
    "\n",
    "        if all([tr.endswith(\"endofseq\") for _, tr in top_translations]):\n",
    "            return top_translations[0][1].replace(\"endofseq\", \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc963ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:12:56.863527Z",
     "iopub.status.busy": "2025-06-19T07:12:56.862517Z",
     "iopub.status.idle": "2025-06-19T07:12:57.575117Z",
     "shell.execute_reply": "2025-06-19T07:12:57.574152Z"
    },
    "papermill": {
     "duration": 1.189354,
     "end_time": "2025-06-19T07:12:57.576858",
     "exception": false,
     "start_time": "2025-06-19T07:12:56.387504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta [UNK] ella antes de ir a la playa'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_en = \"I like soccer and also going to the beach\"\n",
    "translate(sentence_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "081a82d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:12:58.592465Z",
     "iopub.status.busy": "2025-06-19T07:12:58.592122Z",
     "iopub.status.idle": "2025-06-19T07:14:02.073225Z",
     "shell.execute_reply": "2025-06-19T07:14:02.072318Z"
    },
    "papermill": {
     "duration": 64.499392,
     "end_time": "2025-06-19T07:14:02.607031",
     "exception": false,
     "start_time": "2025-06-19T07:12:58.107639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Top first words: [(-0.0048767435, 'me'), (-5.995707, 'a'), (-7.161818, 'se')]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Top translations so far: [(-0.021505108, 'me gusta'), (-4.168967, 'me gustan'), (-6.6700883, 'a mí')]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Top translations so far: [(-1.4461229, 'me gusta [UNK]'), (-1.7645427, 'me gusta la'), (-1.8998783, 'me gusta que')]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Top translations so far: [(-2.4531894, 'me gusta la estación'), (-2.9508576, 'me gusta la chica'), (-2.967947, 'me gusta que [UNK]')]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Top translations so far: [(-2.8418884, 'me gusta la estación y'), (-3.7337677, 'me gusta la chica que'), (-3.9009368, 'me gusta que [UNK] [UNK]')]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Top translations so far: [(-3.4586139, 'me gusta la estación y me'), (-4.0285234, 'me gusta que [UNK] [UNK] a'), (-4.175418, 'me gusta la estación y a')]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Top translations so far: [(-3.5529494, 'me gusta la estación y me gusta'), (-4.070143, 'me gusta que [UNK] [UNK] a la'), (-5.2871118, 'me gusta la estación y a mi')]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Top translations so far: [(-4.13051, 'me gusta que [UNK] [UNK] a la playa'), (-4.464407, 'me gusta la estación y me gusta ir'), (-4.7244396, 'me gusta la estación y me gusta a')]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Top translations so far: [(-4.144605, 'me gusta que [UNK] [UNK] a la playa endofseq'), (-4.5227547, 'me gusta la estación y me gusta ir a'), (-5.567013, 'me gusta la estación y me gusta a tocar')]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Top translations so far: [(-4.144605, 'me gusta que [UNK] [UNK] a la playa endofseq'), (-4.564497, 'me gusta la estación y me gusta ir a la'), (-5.843459, 'me gusta la estación y me gusta a tocar endofseq')]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Top translations so far: [(-4.144605, 'me gusta que [UNK] [UNK] a la playa endofseq'), (-4.7649245, 'me gusta la estación y me gusta ir a la playa'), (-5.843459, 'me gusta la estación y me gusta a tocar endofseq')]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Top translations so far: [(-4.144605, 'me gusta que [UNK] [UNK] a la playa endofseq'), (-4.765103, 'me gusta la estación y me gusta ir a la playa endofseq'), (-5.843459, 'me gusta la estación y me gusta a tocar endofseq')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'me gusta que [UNK] [UNK] a la playa'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search(sentence_en, beam_width=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f57036f",
   "metadata": {
    "papermill": {
     "duration": 0.532807,
     "end_time": "2025-06-19T07:14:03.621455",
     "exception": false,
     "start_time": "2025-06-19T07:14:03.088648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Sampling (Nucleus Sampling, Temperature Sampling, Top-k Sampling)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8280358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:14:04.605842Z",
     "iopub.status.busy": "2025-06-19T07:14:04.605475Z",
     "iopub.status.idle": "2025-06-19T07:14:04.616861Z",
     "shell.execute_reply": "2025-06-19T07:14:04.615903Z"
    },
    "papermill": {
     "duration": 0.496026,
     "end_time": "2025-06-19T07:14:04.618661",
     "exception": false,
     "start_time": "2025-06-19T07:14:04.122635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Utility to convert logits to token\n",
    "def sample_token_from_probs(probs, temperature=1.0):\n",
    "    probs = np.asarray(probs)\n",
    "    if temperature != 1.0:\n",
    "        probs = np.log(probs + 1e-9) / temperature\n",
    "        probs = np.exp(probs) / np.sum(np.exp(probs))\n",
    "    return np.random.choice(len(probs), p=probs)\n",
    "\n",
    "# Top-k Sampling\n",
    "def top_k_sampling(sentence_en, k=10, temperature=1.0):\n",
    "    translation = \"\"\n",
    "    for idx in range(max_length):\n",
    "        X = np.array([sentence_en])\n",
    "        X_dec = np.array([\"startofseq \" + translation])\n",
    "        y_proba = model.predict((X, X_dec))[0, idx]\n",
    "        \n",
    "        top_k_indices = np.argsort(y_proba)[-k:]\n",
    "        top_k_probs = y_proba[top_k_indices]\n",
    "        top_k_probs = top_k_probs / np.sum(top_k_probs)  # Normalize\n",
    "        sampled_index = np.random.choice(top_k_indices, p=top_k_probs)\n",
    "        \n",
    "        word = text_vec_layer_es.get_vocabulary()[sampled_index]\n",
    "        if word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + word\n",
    "    return translation.strip()\n",
    "\n",
    "# Nucleus (Top-p) Sampling\n",
    "def nucleus_sampling(sentence_en, p=0.9, temperature=1.0):\n",
    "    translation = \"\"\n",
    "    for idx in range(max_length):\n",
    "        X = np.array([sentence_en])\n",
    "        X_dec = np.array([\"startofseq \" + translation])\n",
    "        y_proba = model.predict((X, X_dec))[0, idx]\n",
    "        \n",
    "        sorted_indices = np.argsort(y_proba)[::-1]\n",
    "        sorted_probs = y_proba[sorted_indices]\n",
    "        cumulative_probs = np.cumsum(sorted_probs)\n",
    "        \n",
    "        cutoff = np.where(cumulative_probs > p)[0][0] + 1\n",
    "        top_p_indices = sorted_indices[:cutoff]\n",
    "        top_p_probs = y_proba[top_p_indices]\n",
    "        top_p_probs = top_p_probs / np.sum(top_p_probs)\n",
    "        \n",
    "        sampled_index = np.random.choice(top_p_indices, p=top_p_probs)\n",
    "        word = text_vec_layer_es.get_vocabulary()[sampled_index]\n",
    "        if word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + word\n",
    "    return translation.strip()\n",
    "\n",
    "# Temperature Sampling\n",
    "def temperature_sampling(sentence_en, temperature=1.0):\n",
    "    translation = \"\"\n",
    "    for idx in range(max_length):\n",
    "        X = np.array([sentence_en])\n",
    "        X_dec = np.array([\"startofseq \" + translation])\n",
    "        y_proba = model.predict((X, X_dec))[0, idx]\n",
    "        \n",
    "        sampled_index = sample_token_from_probs(y_proba, temperature)\n",
    "        word = text_vec_layer_es.get_vocabulary()[sampled_index]\n",
    "        if word == \"endofseq\":\n",
    "            break\n",
    "        translation += \" \" + word\n",
    "    return translation.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04fd5282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:14:05.658524Z",
     "iopub.status.busy": "2025-06-19T07:14:05.657632Z",
     "iopub.status.idle": "2025-06-19T07:14:07.620867Z",
     "shell.execute_reply": "2025-06-19T07:14:07.620022Z"
    },
    "papermill": {
     "duration": 2.458321,
     "end_time": "2025-06-19T07:14:07.622606",
     "exception": false,
     "start_time": "2025-06-19T07:14:05.164285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Top-k Sampling: me gusta como a la chica a la playa\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Nucleus Sampling: me gusta como la estación antes de ir a la playa\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Temperature Sampling (0.7): me gusta la chica cuando estoy al fútbol\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I like soccer and also going to the beach\"\n",
    "\n",
    "print(\"Top-k Sampling:\", top_k_sampling(sentence, k=10))\n",
    "print(\"Nucleus Sampling:\", nucleus_sampling(sentence, p=0.9))\n",
    "print(\"Temperature Sampling (0.7):\", temperature_sampling(sentence, temperature=0.7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ada52def",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:14:08.643744Z",
     "iopub.status.busy": "2025-06-19T07:14:08.643395Z",
     "iopub.status.idle": "2025-06-19T07:14:08.649641Z",
     "shell.execute_reply": "2025-06-19T07:14:08.648907Z"
    },
    "papermill": {
     "duration": 0.493438,
     "end_time": "2025-06-19T07:14:08.651439",
     "exception": false,
     "start_time": "2025-06-19T07:14:08.158001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def temperature_sampling_range(sentence_en, temperatures=[0.4, 0.5, 0.6, 0.7, 0.8]):\n",
    "    results = {}\n",
    "    for temp in temperatures:\n",
    "        translation = \"\"\n",
    "        for idx in range(max_length):\n",
    "            X = np.array([sentence_en])\n",
    "            X_dec = np.array([\"startofseq \" + translation])\n",
    "            y_proba = model.predict((X, X_dec))[0, idx]\n",
    "\n",
    "            # Apply temperature scaling\n",
    "            scaled_logits = np.log(y_proba + 1e-9) / temp\n",
    "            scaled_probs = np.exp(scaled_logits)\n",
    "            scaled_probs /= np.sum(scaled_probs)\n",
    "\n",
    "            sampled_index = np.random.choice(len(scaled_probs), p=scaled_probs)\n",
    "            word = text_vec_layer_es.get_vocabulary()[sampled_index]\n",
    "            if word == \"endofseq\":\n",
    "                break\n",
    "            translation += \" \" + word\n",
    "\n",
    "        results[temp] = translation.strip()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72392d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-19T07:14:09.668064Z",
     "iopub.status.busy": "2025-06-19T07:14:09.667226Z",
     "iopub.status.idle": "2025-06-19T07:14:12.846050Z",
     "shell.execute_reply": "2025-06-19T07:14:12.845214Z"
    },
    "papermill": {
     "duration": 3.666401,
     "end_time": "2025-06-19T07:14:12.847726",
     "exception": false,
     "start_time": "2025-06-19T07:14:09.181325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Temperature 0.4: me gusta [UNK] a ella y a la playa\n",
      "Temperature 0.5: me gusta cuando [UNK] a la playa\n",
      "Temperature 0.6: me gusta que ella [UNK] a la playa a la playa\n",
      "Temperature 0.7: me gusta [UNK] antes de ir a la playa\n",
      "Temperature 0.8: me gusta que me gusta ella y a la playa\n"
     ]
    }
   ],
   "source": [
    "translations = temperature_sampling_range(sentence, temperatures=[0.4, 0.5, 0.6, 0.7, 0.8])\n",
    "for temp, result in translations.items():\n",
    "    print(f\"Temperature {temp}: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 790.343016,
   "end_time": "2025-06-19T07:14:16.949176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-19T07:01:06.606160",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
